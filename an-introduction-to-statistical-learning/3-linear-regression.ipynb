{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(y_name, X_name, data):\n",
    "    y = data.loc[:, y_name]\n",
    "    X = sm.add_constant(data.loc[:, X_name].values)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return show_table(model, X_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table(model, X_name):\n",
    "    index_name = ['Intercept']\n",
    "\n",
    "    if isinstance(X_name, str):\n",
    "        index_name.append(X_name)\n",
    "    elif isinstance(X_name, list):\n",
    "        index_name = index_name + X_name\n",
    "\n",
    "    df = pd.read_html(model.summary2().as_html())[1]\n",
    "    colname = df.iloc[0]\n",
    "    df = df.rename(columns=df.iloc[0]).drop(0).set_index(np.nan)\n",
    "    df.index.name = None\n",
    "    df.index = index_name\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_VIF(columns, data):\n",
    "    X = data.loc[:, columns]\n",
    "    X.loc[:, 'Intercept'] = 1\n",
    "      \n",
    "    vif = pd.DataFrame()\n",
    "    vif.loc[:, 'variables'] = X.columns\n",
    "    vif.loc[:, 'VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "      \n",
    "    return vif.drop(vif.tail(1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising = pd.read_csv('data/Advertising.csv')\n",
    "credit = pd.read_csv('data/Credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.2\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV']]\n",
    "X = sm.add_constant(X)\n",
    "slr = sm.OLS(y, X).fit()\n",
    "rss = slr.resid.std(ddof=X.shape[1])\n",
    "print(f'RSS: {rss}')\n",
    "slr.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.1\n",
    "compute_model('sales', 'TV', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.3\n",
    "compute_model('sales', 'radio', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.3\n",
    "compute_model('sales', 'newspaper', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.4\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV', 'radio', 'newspaper']]\n",
    "X = sm.add_constant(X)\n",
    "mlr = sm.OLS(y, X).fit()\n",
    "mlr.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.6\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV', 'radio', 'newspaper']]\n",
    "X = sm.add_constant(X)\n",
    "mlr = sm.OLS(y, X).fit()\n",
    "rss = mlr.resid.std(ddof=X.shape[1])\n",
    "print(f'RSS: {rss}')\n",
    "mlr.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.7\n",
    "credit_owner_dummy = pd.get_dummies(credit, columns=['Own'])\n",
    "compute_model('Balance', 'Own_Yes', credit_owner_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.8\n",
    "credit_region_dummy = pd.get_dummies(credit, columns=['Region'])\n",
    "compute_model('Balance', ['Region_West', 'Region_South'], credit_region_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.9\n",
    "advertising['TVxradio'] = advertising['TV'] * advertising['radio']\n",
    "compute_model('sales', ['TV', 'radio', 'TVxradio'], advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.11\n",
    "groupby_cols = ['model', 'column']\n",
    "\n",
    "model_1_df = compute_model('Balance', ['Age', 'Limit'], credit)\n",
    "model_1_df['model'] = 'Model 1'\n",
    "model_2_df = compute_model('Balance', ['Rating', 'Limit'], credit)\n",
    "model_2_df['model'] = 'Model 2'\n",
    "\n",
    "model_df = pd.concat([model_1_df, model_2_df]).reset_index()\n",
    "model_df.rename(columns = {'index': 'column'}, inplace=True)\n",
    "model_df = model_df.groupby(groupby_cols, group_keys=True).apply(lambda a: a[:])\n",
    "model_df[model_df.columns.drop(groupby_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_VIF(['TV', 'radio', 'newspaper'], advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS, summarize, poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Avenir'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXPORT_CONFIG = {\n",
    "    'dpi': 500,\n",
    "    'bbox_inches': 'tight',\n",
    "    'pad_inches': 0.15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_palette('hls', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `boston` dataset records `medv` (median house value) for 506 neighborhoods around Boston. \n",
    "\n",
    "We will build a regression model to predict `medv` using **13** predictors such as:\n",
    "- `rmvar` (average number of rooms per house),\n",
    "- `age` (proportion of owner-occupied units built prior to 1940), and\n",
    "- `lstat` (percent of households with low socioeconomic status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = load_data('Boston')\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston_df?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "\n",
    "Our response will be `medv` and `lstat` will be the single predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\n",
    "    'intercept': np.ones(boston_df.shape[0]),\n",
    "    'lstat': boston_df['lstat'],\n",
    "})\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sm.OLS()` does not fit the model, rather it specifies the model, and then `model.fit()` does the actual fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston_df['medv']\n",
    "slr = sm.OLS(y, X)\n",
    "slr_result = slr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(slr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slr_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Transformations: Fit and Transform\n",
    "\n",
    "`ModelSpec()` (renamed `MS()` in the preamble) creates a transform object, and then a pair of methods `transform()` and `fit()` are used to construct a corresponding model matrix.\n",
    "\n",
    "In this simple case, the `fit()` method does very little; it simply checks that the variable `lstat` specified in design exists in `boston`. Then `transform()` constructs the model matrix with two columns: an intercept and the variable `lstat`.\n",
    "\n",
    "These two operations can be combined with the `fit_transform() `method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(['lstat'])\n",
    "# option 1\n",
    "design = design.fit(boston_df)\n",
    "X = design.transform(boston_df)\n",
    "# option 2\n",
    "X = design.fit_transform(boston_df)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_prediction()` method can be used to obtain predictions, and produce confidence intervals and prediction intervals for the prediction of `medv` for given values of `lstat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'lstat': [5, 10, 15]})\n",
    "new_X = design.transform(new_df)\n",
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = slr_result.get_prediction(new_X)\n",
    "new_pred.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence interval\n",
    "new_pred.conf_int(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction internal\n",
    "new_pred.conf_int(obs=True, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 95% confidence interval associated with an `lstat` value of 10 is (24.47, 25.63), and the 95% prediction interval is (12.82, 37.28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linear_line(ax, m, b, *args, **kwargs):\n",
    "    \"\"\" Add a line with slope m and intercept b to ax \"\"\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = [m * xlim[0] + b, m * xlim[1] + b]\n",
    "    ax.plot(xlim, ylim, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x='lstat', y='medv', data=boston_df, ax=ax)\n",
    "add_linear_line(ax, slr_result.params[1], slr_result.params[0], 'r--')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the fitted values (`.fittedvalues`) against theirs residuals (`.resid`). We add a horizontal line at `0` for reference using the `ax.axhline()` method, indicating it should be black (`c='k'`) and have a dashed linestyle (`ls='--'`).\n",
    "\n",
    "From the plot, there is some evidence of non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(slr_result.fittedvalues, slr_result.resid)\n",
    "ax.set_xlabel('Fitted value')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.axhline(0, c='k', ls='--')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various influence measures describing the regression model are computed with the `get_influence()` method.\n",
    "\n",
    "Leverage statistics can be computed for any number of predictors using the `hat_matrix_diag` attribute of the value returned by the `get_influence()` method.\n",
    "\n",
    "The `np.argmax()` function identifies the index of the largest element of an array, optionally computed over an axis of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = slr_result.get_influence()\n",
    "influence.summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(np.arange(X.shape[0]), influence.hat_matrix_diag)\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Leverage')\n",
    "np.argmax(influence.hat_matrix_diag)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "In order to fit a multiple linear regression model using least squares, we again use the `ModelSpec()` transform to construct the required model matrix and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MS(['lstat', 'age']).fit_transform(boston_df)\n",
    "mlr = sm.OLS(y, X)\n",
    "mlr_result = mlr.fit()\n",
    "summarize(mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use all columns to predict `medv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = boston_df.columns.drop('medv')\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = MS(terms).fit_transform(boston_df)\n",
    "new_mlr = sm.OLS(y, new_X)\n",
    "new_mlr_result = mlr.fit()\n",
    "summarize(new_mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summarize, we see that `indus` and `age` has high $p$-value. So we'd remove these 2 columns from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = boston_df.columns.drop(['medv', 'indus', 'age'])\n",
    "new_X = MS(new_terms).fit_transform(boston_df)\n",
    "new_mlr = sm.OLS(y, new_X)\n",
    "new_mlr_result = new_mlr.fit()\n",
    "summarize(new_mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Goodness of Fit\n",
    "\n",
    "#### List Comprehension\n",
    "\n",
    "**Variance Inflation Factor (VIF):** is the ratio of the variance of $\\hat\\beta_j$ when fitting the full model divided by the variance of $\\hat\\beta_j$ if fit on its own.\n",
    "\n",
    "Function `VIF()` takes 2 arguments: a dataframe or array, and a variable column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(X, i) for i in range(1, X.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals}, index=X.columns[1:])\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Terms\n",
    "\n",
    "**Interaction Term:** constructed by computing the product of $X_1$ and $X_2$.\n",
    "\n",
    "⟹ Extended model: $$Y = \\beta_0 + \\beta_1X1 + \\beta_2X_2 + \\beta_3X_1X_2 + \\epsilon$$\n",
    "\n",
    "Including a tuple `('lstat', 'age')` tells the model matrix builder to include an interaction term between `lstat` and `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = MS(['lstat', 'age', ('lstat', 'age')]).fit_transform(boston_df)\n",
    "mlr_2 = sm.OLS(y, X_2)\n",
    "mlr_result_2 = mlr_2.fit()\n",
    "summarize(mlr_result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear Transformations of the Predictors\n",
    "\n",
    "Function `poly()` supplied in `ISLP` creates a basis matrix for inclusion in the model matrix whose columns are *orthogonal polynomials*, which are designed for stable least squares computations.\n",
    "\n",
    "It specifies that columns representing polynomial functions of its first argument are added to the model matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = MS(terms=[poly(col='lstat', degree=2), 'age']).fit_transform(boston_df)\n",
    "mlr_3 = sm.OLS(y, X_3)\n",
    "mlr_result_3 = mlr_3.fit()\n",
    "summarize(mlr_result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero $p$-value associated with the quadratic term (`poly(lstat, degree=2)[1]`) suggests that this is an improved model.\n",
    "\n",
    "The `anova_lm` function performs a hypothesis test comparing the 2 models.\n",
    "- $H_0$: quadratic term in the bigger model is not need\n",
    "- $H_a$: the bigger model is superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_lm(mlr_result, mlr_result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the $F$-statistic os 177.28 and the associated $p$-value is zero. The $F$-statistic is the square of the $t$-statistic for the quadratic term in the linear model summary for `mlr_result_3` -- a consequence of the fact that these nested models differ by 1 degree of freedom.\n",
    "\n",
    "⟹ Reject null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.scatterplot(data=pd.DataFrame({\n",
    "    'fittedvalues': mlr_result_3.fittedvalues,\n",
    "    'resid': mlr_result_3.resid,\n",
    "}), x='fittedvalues', y='resid')\n",
    "ax.set_xlabel('Fitted Value')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.axhline(0, c='k', ls='--')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Predictors\n",
    "\n",
    "`Carseats` dataset includes qualitative predictors such as `ShelveLoc`, an indicator of the quality of the shelving location, and takes 3 values `Bad`, `Medium`, and `Good`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carseats_df = load_data('Carseats')\n",
    "carseats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-matrix builder has created:\n",
    "- `ShelveLoc[Good]` dummy variable that takes on a value of 1 if the shelving location is `good`, and 0 otherwise\n",
    "- `ShelveLoc[Medium]` dummy variable that equals 1 if the shelving location is `medium`, and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = list(carseats_df.columns.drop('Sales'))\n",
    "terms += [('Income', 'Advertising'), ('Price', 'Age')]\n",
    "y = carseats_df['Sales']\n",
    "X = MS(terms).fit_transform(carseats_df)\n",
    "mlr = sm.OLS(y, X)\n",
    "mlr_result = mlr.fit()\n",
    "summarize(mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for `ShelveLoc[Good]` > 0 indicates that a `good` shelving location is associated with high sales (relative to a bad location). And `ShelveLoc[Medium]` has a smaller positive coefficient, indicating that a `medium` shelving location leads to lower sales than a `good` shelving location and higher sales than a `bad` shelving location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS, summarize, poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Avenir'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXPORT_CONFIG = {\n",
    "    'dpi': 500,\n",
    "    'bbox_inches': 'tight',\n",
    "    'pad_inches': 0.15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_palette('hls', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(y_name, X_name, data):\n",
    "    y = data.loc[:, y_name]\n",
    "    X = sm.add_constant(data.loc[:, X_name].values)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    return model, show_table(model, X_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table(model, X_name):\n",
    "    index_name = ['Intercept']\n",
    "    if isinstance(X_name, str):\n",
    "        index_name.append(X_name)\n",
    "    elif isinstance(X_name, list):\n",
    "        index_name = index_name + X_name\n",
    "    \n",
    "    df = pd.read_html(model.summary2().as_html())[1]\n",
    "    colname = df.iloc[0]\n",
    "    df = df.rename(columns=df.iloc[0]).drop(0).set_index(np.nan)\n",
    "    df.index.name = None\n",
    "    df.index = index_name\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8 / 129\n",
    "\n",
    "(a) Use the `sm.OLS()` function to perform a simple linear regression with `mpg` as the response and `horsepower` as the predictor. Use the `summarize()` function to print the results. Comment on the output. For example:\n",
    "\n",
    "1. Is there a relationship between the predictor and the response?\n",
    "2. How strong is the relationship between the predictor and the response?\n",
    "3. Is the relationship between the predictor and the response positive or negative?\n",
    "4. What is the predicted `mpg` associated with a `horsepower` of 98? What are the associated 95% confidence and prediction intervals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = pd.read_csv('data/Auto.csv')\n",
    "auto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_df = pd.DataFrame({\n",
    "    'mpg': pd.to_numeric(auto_df['mpg'], errors='coerce'),\n",
    "    'horsepower': pd.to_numeric(auto_df['horsepower'], errors='coerce'),\n",
    "}).dropna()\n",
    "slr_result, slr_summary = compute_model('mpg', 'horsepower', slr_df)\n",
    "slr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_result.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(['horsepower'])\n",
    "X = design.fit_transform(slr_df)\n",
    "new_df = pd.DataFrame({'horsepower': [98]})\n",
    "new_X = design.transform(new_df)\n",
    "new_pred = slr_result.get_prediction(new_X)\n",
    "print(f'Confidence Interval: {new_pred.conf_int(alpha=0.05)}')\n",
    "print(f'Prediction Interval: {new_pred.conf_int(obs=True, alpha=0.05)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The small $p$-values indicates that there is a statistically significant relationship between the `horsepower` and `mpg`.\n",
    "2. From the 2nd table, we see that `horsepower` explains 60.6% of the variance in `mpg`.\n",
    "3. We can see that the coefficient of `horsepower` is a negative number, hence, the relationship between `horsepower` and `mpg` is negative.\n",
    "4. The predicted `mpg` associated with a `horsepower` of 98 is: $= 39.9359 + 98 \\times (-0.1578) = 24.4715$. <br>\n",
    "    The 95% confidence interval is [-65.0684 -52.0335] and that of predicted interval is [-72.3933, -44.7087]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Plot the response and the predictor in a new set of axes `ax`. Use the `ax.axline()` method or the `abline()` function defined in the lab to display the least squares regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linear_line(ax, m, b, *args, **kwargs):\n",
    "    \"\"\" Add a line with slope m and intercept b to ax \"\"\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = [m * xlim[0] + b, m * xlim[1] + b]\n",
    "    ax.plot(xlim, ylim, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x='horsepower', y='mpg', data=slr_df, ax=ax)\n",
    "add_linear_line(ax, slr_result.params[1], slr_result.params[0], 'r--')\n",
    "ax.set_title('Linear Model of mpg vs horsepower')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Produce some of diagnostic plots of the least squares regression fit as described in the lab. Comment on any problems you see with the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_values = slr_result.fittedvalues\n",
    "resid = slr_result.resid\n",
    "student_resid = slr_result.outlier_test()['student_resid']\n",
    "leverage_resid = slr_result.get_influence().hat_matrix_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_1_df = pd.DataFrame({\n",
    "    'fittedvalues': fitted_values,\n",
    "    'resid': resid,\n",
    "})\n",
    "auto_2_df = pd.DataFrame({\n",
    "    'fittedvalues': fitted_values,\n",
    "    'sqrt_student_resid': np.sqrt(np.abs(student_resid)),\n",
    "})\n",
    "auto_3_df = pd.DataFrame({\n",
    "    'leverage': leverage_resid,\n",
    "    'student_resid': student_resid,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(6, 10))\n",
    "\n",
    "sns.regplot(data=auto_1_df, x='fittedvalues', y='resid', order=4, ax=axes[0])\n",
    "axes[0].set_xlabel('Fitted value')\n",
    "axes[0].set_ylabel('Residual')\n",
    "axes[0].set_title('Residual vs. Fitted value')\n",
    "\n",
    "sns.regplot(data=auto_2_df, x='fittedvalues', y='sqrt_student_resid', order=4, ax=axes[1])\n",
    "axes[1].set_xlabel('Fitted value')\n",
    "axes[1].set_ylabel('Squared studentized residual')\n",
    "axes[1].set_title('Squared studentized residual vs. Fitted value')\n",
    "\n",
    "sns.regplot(data=auto_3_df, x='leverage', y='student_resid', order=4, ax=axes[2])\n",
    "axes[2].set_xlabel('Fitted value')\n",
    "axes[2].set_ylabel('Leverage residual')\n",
    "axes[2].set_title('Leverage residual vs. Fitted value')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
