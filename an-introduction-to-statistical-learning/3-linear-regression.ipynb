{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(y_name, X_name, data):\n",
    "    y = data.loc[:, y_name]\n",
    "    X = sm.add_constant(data.loc[:, X_name].values)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return show_table(model, X_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table(model, X_name):\n",
    "    index_name = ['Intercept']\n",
    "\n",
    "    if isinstance(X_name, str):\n",
    "        index_name.append(X_name)\n",
    "    elif isinstance(X_name, list):\n",
    "        index_name = index_name + X_name\n",
    "\n",
    "    df = pd.read_html(model.summary2().as_html())[1]\n",
    "    colname = df.iloc[0]\n",
    "    df = df.rename(columns=df.iloc[0]).drop(0).set_index(np.nan)\n",
    "    df.index.name = None\n",
    "    df.index = index_name\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_VIF(columns, data):\n",
    "    X = data.loc[:, columns]\n",
    "    X.loc[:, 'Intercept'] = 1\n",
    "      \n",
    "    vif = pd.DataFrame()\n",
    "    vif.loc[:, 'variables'] = X.columns\n",
    "    vif.loc[:, 'VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "      \n",
    "    return vif.drop(vif.tail(1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising = pd.read_csv('data/Advertising.csv')\n",
    "credit = pd.read_csv('data/Credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.2\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV']]\n",
    "X = sm.add_constant(X)\n",
    "slr = sm.OLS(y, X).fit()\n",
    "rss = slr.resid.std(ddof=X.shape[1])\n",
    "print(f'RSS: {rss}')\n",
    "slr.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.1\n",
    "compute_model('sales', 'TV', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.3\n",
    "compute_model('sales', 'radio', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.3\n",
    "compute_model('sales', 'newspaper', advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.4\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV', 'radio', 'newspaper']]\n",
    "X = sm.add_constant(X)\n",
    "mlr = sm.OLS(y, X).fit()\n",
    "mlr.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.6\n",
    "y = advertising['sales']\n",
    "X = advertising[['TV', 'radio', 'newspaper']]\n",
    "X = sm.add_constant(X)\n",
    "mlr = sm.OLS(y, X).fit()\n",
    "rss = mlr.resid.std(ddof=X.shape[1])\n",
    "print(f'RSS: {rss}')\n",
    "mlr.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.7\n",
    "credit_owner_dummy = pd.get_dummies(credit, columns=['Own'])\n",
    "compute_model('Balance', 'Own_Yes', credit_owner_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.8\n",
    "credit_region_dummy = pd.get_dummies(credit, columns=['Region'])\n",
    "compute_model('Balance', ['Region_West', 'Region_South'], credit_region_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.9\n",
    "advertising['TVxradio'] = advertising['TV'] * advertising['radio']\n",
    "compute_model('sales', ['TV', 'radio', 'TVxradio'], advertising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 3.11\n",
    "groupby_cols = ['model', 'column']\n",
    "\n",
    "model_1_df = compute_model('Balance', ['Age', 'Limit'], credit)\n",
    "model_1_df['model'] = 'Model 1'\n",
    "model_2_df = compute_model('Balance', ['Rating', 'Limit'], credit)\n",
    "model_2_df['model'] = 'Model 2'\n",
    "\n",
    "model_df = pd.concat([model_1_df, model_2_df]).reset_index()\n",
    "model_df.rename(columns = {'index': 'column'}, inplace=True)\n",
    "model_df = model_df.groupby(groupby_cols, group_keys=True).apply(lambda a: a[:])\n",
    "model_df[model_df.columns.drop(groupby_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_VIF(['TV', 'radio', 'newspaper'], advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS, summarize, poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Avenir'\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXPORT_CONFIG = {\n",
    "    'dpi': 500,\n",
    "    'bbox_inches': 'tight',\n",
    "    'pad_inches': 0.15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "sns.set_palette('hls', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `boston` dataset records `medv` (median house value) for 506 neighborhoods around Boston. \n",
    "\n",
    "We will build a regression model to predict `medv` using **13** predictors such as:\n",
    "- `rmvar` (average number of rooms per house),\n",
    "- `age` (proportion of owner-occupied units built prior to 1940), and\n",
    "- `lstat` (percent of households with low socioeconomic status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = load_data('Boston')\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston_df?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our response will be `medv` and `lstat` will be the single predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\n",
    "    'intercept': np.ones(boston_df.shape[0]),\n",
    "    'lstat': boston_df['lstat'],\n",
    "})\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sm.OLS()` does not fit the model, rather it specifies the model, and then `model.fit()` does the actual fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston_df['medv']\n",
    "slr = sm.OLS(y, X)\n",
    "slr_result = slr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(slr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slr_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Transformations: Fit and Transform\n",
    "\n",
    "`ModelSpec()` (renamed `MS()` in the preamble) creates a transform object, and then a pair of methods `transform()` and `fit()` are used to construct a corresponding model matrix.\n",
    "\n",
    "In this simple case, the `fit()` method does very little; it simply checks that the variable `lstat` specified in design exists in `boston`. Then `transform()` constructs the model matrix with two columns: an intercept and the variable `lstat`.\n",
    "\n",
    "These two operations can be combined with the `fit_transform() `method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = MS(['lstat'])\n",
    "# option 1\n",
    "design = design.fit(boston_df)\n",
    "X = design.transform(boston_df)\n",
    "# option 2\n",
    "X = design.fit_transform(boston_df)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_prediction()` method can be used to obtain predictions, and produce confidence intervals and prediction intervals for the prediction of `medv` for given values of `lstat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'lstat': [5, 10, 15]})\n",
    "new_X = design.transform(new_df)\n",
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = slr_result.get_prediction(new_X)\n",
    "new_pred.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence interval\n",
    "new_pred.conf_int(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction internal\n",
    "new_pred.conf_int(obs=True, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 95% confidence interval associated with an `lstat` value of 10 is (24.47, 25.63), and the 95% prediction interval is (12.82, 37.28)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linear_line(ax, m, b, *args, **kwargs):\n",
    "    \"\"\" Add a line with slope m and intercept b to ax \"\"\"\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = [m * xlim[0] + b, m * xlim[1] + b]\n",
    "    ax.plot(xlim, ylim, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x='lstat', y='medv', data=boston_df, ax=ax)\n",
    "add_linear_line(ax, slr_result.params[0], slr_result.params[1], 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the fitted values (`.fittedvalues`) against theirs residuals (`.resid`). We add a horizontal line at `0` for reference using the `ax.axhline()` method, indicating it should be black (`c='k'`) and have a dashed linestyle (`ls='--'`).\n",
    "\n",
    "From the plot, there is some evidence of non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize=(8, 8))[1]\n",
    "ax.scatter(slr_result.fittedvalues, slr_result.resid)\n",
    "ax.set_xlabel('Fitted value')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.axhline(0, c='k', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various influence measures describing the regression model are computed with the `get_influence()` method.\n",
    "\n",
    "Leverage statistics can be computed for any number of predictors using the `hat_matrix_diag` attribute of the value returned by the `get_influence()` method.\n",
    "\n",
    "The `np.argmax()` function identifies the index of the largest element of an array, optionally computed over an axis of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = slr_result.get_influence()\n",
    "influence.summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize=(8, 8))[1]\n",
    "ax.scatter(np.arange(X.shape[0]), influence.hat_matrix_diag)\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_ylabel('Leverage')\n",
    "np.argmax(influence.hat_matrix_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit a multiple linear regression model using least squares, we again use the `ModelSpec()` transform to construct the required model matrix and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MS(['lstat', 'age']).fit_transform(boston_df)\n",
    "mlr = sm.OLS(y, X)\n",
    "mlr_result = mlr.fit()\n",
    "summarize(mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use all columns to predict `medv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = boston_df.columns.drop('medv')\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MS(terms).fit_transform(boston_df)\n",
    "mlr = sm.OLS(y, X)\n",
    "mlr_result = mlr.fit()\n",
    "summarize(mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summarize, we see that `indus` and `age` has high $p$-value. So we'd remove these 2 columns from the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = boston_df.columns.drop(['medv', 'indus', 'age'])\n",
    "new_X = MS(new_terms).fit_transform(boston_df)\n",
    "new_mlr = sm.OLS(y, new_X)\n",
    "new_mlr_result = new_mlr.fit()\n",
    "summarize(new_mlr_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Goodness of Fit\n",
    "\n",
    "#### List Comprehension\n",
    "\n",
    "**Variance Inflation Factor (VIF):** is the ratio of the variance of $\\hat\\beta_j$ when fitting the full model divided by the variance of $\\hat\\beta_j$ if fit on its own.\n",
    "\n",
    "Function `VIF()` takes 2 arguments: a dataframe or array, and a variable column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [VIF(X, i) for i in range(1, X.shape[1])]\n",
    "vif = pd.DataFrame({'vif': vals}, index=X.columns[1:])\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Terms\n",
    "\n",
    "**Interaction Term:** constructed by computing the product of $X_1$ and $X_2$.\n",
    "\n",
    "‚üπ Extended model: $$Y = \\beta_0 + \\beta_1X1 + \\beta_2X_2 + \\beta_3X_1X_2 + \\epsilon$$\n",
    "\n",
    "Including a tuple `('lstat', 'age')` tells the model matrix builder to include an interaction term between `lstat` and `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = MS(['lstat', 'age', ('lstat', 'age')]).fit_transform(boston_df)\n",
    "mlr_2 = sm.OLS(y, X_2)\n",
    "mlr_result_2 = mlr_2.fit()\n",
    "summarize(mlr_result_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
